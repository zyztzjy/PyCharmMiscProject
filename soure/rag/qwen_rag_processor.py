# soure/rag/qwen_rag_processor.py
import json
from typing import Dict, List, Optional, Any
from datetime import datetime
from ..embedding.vectorizer_qwen import QwenVectorizer
from ..llm.qwen_completer import QwenWebCompleter
from ..llm.scenario_config import ScenarioConfig, ScenarioRule, ScenarioType
from ..llm.web_search import QwenWebSearcher

import dashscope


class QwenRAGProcessor:
    """ç»Ÿä¸€RAGå¤„ç†å™¨ï¼ˆé›†æˆé€šä¹‰åƒé—®è”ç½‘æœç´¢ï¼‰"""

    def __init__(self,
                 vectorizer: QwenVectorizer,
                 api_key: str,
                 model: str = "qwen-max",
                 config: Optional[Dict] = None):

        self.vectorizer = vectorizer
        self.api_key = api_key
        self.model = model

        # è®¾ç½®APIå¯†é’¥
        dashscope.api_key = api_key

        # é»˜è®¤é…ç½®
        self.default_retrieval_count = 15
        self.similarity_threshold = 0.5

        # åŠ è½½é…ç½®
        self.config = config or {}
        web_config = self.config.get('web_search', {})

        # åˆå§‹åŒ–é€šä¹‰åƒé—®è”ç½‘æœç´¢ç»„ä»¶
        try:
            self.web_searcher = QwenWebSearcher(api_key)
            self.web_completer = QwenWebCompleter(self.web_searcher, web_config)

            # æµ‹è¯•è¿æ¥
            connection_ok, message = self.web_searcher.test_connection()
            if connection_ok:
                print(f"âœ… é€šä¹‰åƒé—®è”ç½‘æœç´¢åŠŸèƒ½å·²å¯ç”¨: {message}")
                self.web_search_enabled = True
            else:
                print(f"âš ï¸ é€šä¹‰åƒé—®APIè¿æ¥æµ‹è¯•å¤±è´¥: {message}")
                print("è”ç½‘æœç´¢åŠŸèƒ½é™çº§ä¸ºæ¨¡æ‹Ÿæ¨¡å¼")
                self.web_search_enabled = False

        except Exception as e:
            print(f"âš ï¸ è”ç½‘æœç´¢åˆå§‹åŒ–å¤±è´¥: {e}")
            self.web_searcher = None
            self.web_completer = None
            self.web_search_enabled = False

    def process_query(
            self,
            query: str,
            scenario: Optional[str] = None,
            company_code: Optional[str] = None,
            use_web_data: str = "auto",
            retrieval_count: Optional[int] = None,
            similarity_threshold: Optional[float] = None,
            web_search_model: Optional[str] = None,
            scenario_rule: Optional[ScenarioRule] = None
    ) -> Dict[str, Any]:
        """
        å¤„ç†RAGæŸ¥è¯¢ï¼ˆé›†æˆé€šä¹‰åƒé—®è”ç½‘æœç´¢ï¼‰
        """
        try:
            start_time = datetime.now()

            # ä½¿ç”¨å‚æ•°æˆ–é»˜è®¤å€¼
            top_k = retrieval_count or self.default_retrieval_count
            threshold = similarity_threshold or self.similarity_threshold

            print(f"å¼€å§‹å¤„ç†æŸ¥è¯¢: {query}")
            print(f"ä¼ä¸š: {company_code or 'æ— '}")
            print(f"åœºæ™¯: {scenario or 'æ— '}")
            print(f"è”ç½‘æœç´¢æ¨¡å¼: {use_web_data}")

            # è·å–åœºæ™¯è§„åˆ™
            # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„åœºæ™¯è§„åˆ™ï¼Œå¦‚æœæœªä¼ å…¥åˆ™æ ¹æ®åœºæ™¯åç§°è·å–
            if not scenario_rule and scenario:
                scenario_rule = ScenarioConfig.get_scenario_by_name(scenario)

            # 1. æœ¬åœ°æ£€ç´¢ - ä¿®å¤è¿™é‡Œï¼Œç¡®ä¿è°ƒç”¨æ­£ç¡®çš„æ–¹æ³•
            local_docs = []
            try:
                if company_code:
                    # ä½¿ç”¨ä¼ä¸šåç§°æœç´¢
                    local_docs = self.vectorizer.search_by_company_name(
                        company_name=company_code,  # æ³¨æ„ï¼šè¿™é‡Œä¼ çš„æ˜¯company_codeï¼Œä½†æ–¹æ³•æœŸæœ›company_name
                        query=query,
                        top_k=top_k * 2,
                        similarity_threshold=0.3
                    )
                else:
                    # å¸¸è§„æœç´¢
                    filters = self._build_filters(scenario, None)
                    local_docs = self.vectorizer.search_similar_documents(
                        query=query,
                        top_k=top_k,
                        filters=filters,
                        company_name=None,  # æ·»åŠ è¿™ä¸ªå‚æ•°
                        scenario=scenario  # æ·»åŠ è¿™ä¸ªå‚æ•°
                    )

                print(f"æœ¬åœ°æ£€ç´¢åˆ° {len(local_docs)} ä¸ªæ–‡æ¡£")

            except Exception as e:
                print(f"æœ¬åœ°æ£€ç´¢å¤±è´¥: {e}")
                local_docs = []

            # 2. è”ç½‘æœç´¢å†³ç­–ä¸æ‰§è¡Œ
            web_docs = []
            web_search_analysis = {
                "performed": False,
                "reason": "æœªå¯ç”¨",
                "confidence": 0.0,
                "query": "",
                "model": web_search_model or self.model,
                "results_count": 0
            }

            if self.web_search_enabled and self.web_completer:
                # åˆ†ææœç´¢éœ€æ±‚
                search_analysis = self.web_completer.analyze_search_need(
                    query=query,
                    local_docs=local_docs,
                    scenario=scenario,
                    company_name=company_code,
                    user_preference=use_web_data
                )

                web_search_analysis.update({
                    "performed": search_analysis["should_search"],
                    "reason": search_analysis["reasons"][0] if search_analysis["reasons"] else "æœªè§¦å‘",
                    "confidence": search_analysis["confidence"],
                    "query": search_analysis["search_query"],
                    "model": search_analysis["model"],
                    "search_type": search_analysis["search_type"]
                })

                # æ‰§è¡Œæœç´¢
                if search_analysis["should_search"]:
                    print(f"æ‰§è¡Œè”ç½‘æœç´¢ï¼Œç±»å‹: {search_analysis['search_type']}")

                    web_docs = self.web_searcher.search(
                        query=search_analysis["search_query"],
                        company_name=company_code,
                        scenario=scenario,
                        model=search_analysis["model"]
                    )

                    web_search_analysis["results_count"] = len(web_docs)
                    print(f"è”ç½‘æœç´¢è·å¾— {len(web_docs)} ä¸ªç»“æœ")
                else:
                    print(f"ä¸æ‰§è¡Œè”ç½‘æœç´¢ï¼ŒåŸå› : {search_analysis['reasons']}")
            else:
                print("è”ç½‘æœç´¢åŠŸèƒ½æœªå¯ç”¨æˆ–ä¸å¯ç”¨")

            # 3. è¿‡æ»¤æœ¬åœ°æ–‡æ¡£
            filtered_local_docs = [
                doc for doc in local_docs
                if doc.get("similarity", 0) >= threshold
            ]
            print(f"æœ¬åœ°æ–‡æ¡£è¿‡æ»¤åå‰©ä½™ {len(filtered_local_docs)} ä¸ª")

            # 4. æ„å»ºå¢å¼ºä¸Šä¸‹æ–‡
            context = self._build_scenario_context(
                local_docs=filtered_local_docs,
                web_docs=web_docs,
                query=query,
                company_code=company_code,
                scenario_rule=scenario_rule,
                web_search_info=web_search_analysis
            )

            # 5. æ„å»ºåœºæ™¯åŒ–æç¤ºè¯
            prompt = self._build_scenario_prompt(
                query=query,
                context=context,
                scenario_rule=scenario_rule,
                company_code=company_code,
                has_web_data=len(web_docs) > 0,
                web_search_info=web_search_analysis
            )

            # 6. è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆå“åº”
            response = self._call_llm(prompt, self.model)

            # 7. è§£æå“åº”
            parsed_response = self._parse_response(response, scenario_rule)

            # 8. å¢å¼ºå“åº”ä¿¡æ¯
            enhanced_response = self._enhance_response(
                parsed_response,
                filtered_local_docs,
                web_docs,
                web_search_analysis,
                scenario_rule
            )

            # 9. è®¡ç®—å¤„ç†æ—¶é—´
            processing_time = (datetime.now() - start_time).total_seconds()

            # 10. æ„å»ºæœ€ç»ˆç»“æœ
            result = self._build_comprehensive_result(
                query=query,
                response=enhanced_response,
                local_docs=filtered_local_docs,
                web_docs=web_docs,
                web_search_analysis=web_search_analysis,
                processing_time=processing_time,
                scenario_name=scenario_rule.display_name if scenario_rule else "è‡ªå®šä¹‰åˆ†æ",
                company_code=company_code,
                threshold=threshold,
                web_mode=use_web_data
            )

            print(f"æŸ¥è¯¢å¤„ç†å®Œæˆï¼Œæ€»è€—æ—¶: {processing_time:.2f}ç§’")

            return result

        except Exception as e:
            print(f"å¤„ç†æŸ¥è¯¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

            return self._build_error_result(query, scenario, company_code, str(e))

    def _retrieve_local_documents(self, query: str, company_code: Optional[str],
                                  scenario: Optional[str], top_k: int) -> List[Dict]:
        """æ£€ç´¢æœ¬åœ°æ–‡æ¡£"""
        if company_code:
            # ä½¿ç”¨ä¼ä¸šåç§°æœç´¢
            return self.vectorizer.search_by_company_name(
                company_name=company_code,
                query=query,
                top_k=top_k * 2,
                similarity_threshold=0.3
            )
        else:
            # å¸¸è§„æœç´¢
            filters = self._build_filters(scenario, None)
            return self.vectorizer.search_similar_documents(
                query=query,
                top_k=top_k,
                filters=filters
            )

    def _build_filters(self, scenario: Optional[str], company_code: Optional[str]) -> Optional[Dict]:
        """æ„å»ºè¿‡æ»¤æ¡ä»¶"""
        if not scenario:
            return None

        scenario_to_type = {
            "æ’¤å¦ä¼ä¸šåˆ†æ": "è´¢åŠ¡æŠ¥å‘Š",
            "é•¿æœŸè¾…å¯¼ä¼ä¸šåˆ†æ": "è´¢åŠ¡æŠ¥å‘Š",
            "å…³ç³»ç½‘åˆ†æ": "æŠ¥å‘Šæ–‡æ¡£"
        }

        if scenario in scenario_to_type:
            return {"document_type": {"$eq": scenario_to_type[scenario]}}

        return None

    def _build_scenario_context(self, local_docs: List[Dict], web_docs: List[Dict],
                                query: str, company_code: Optional[str],
                                scenario_rule: Optional[ScenarioRule],
                                web_search_info: Dict) -> str:
        """æ„å»ºåœºæ™¯åŒ–çš„ä¸Šä¸‹æ–‡"""
        context_parts = []

        # 1. æŸ¥è¯¢ä¿¡æ¯æ¦‚è§ˆ
        context_parts.append("=== åˆ†æä»»åŠ¡æ¦‚è§ˆ ===")
        context_parts.append(f"ğŸ“‹ åŸå§‹æŸ¥è¯¢: {query}")
        if company_code:
            context_parts.append(f"ğŸ¢ ç›®æ ‡ä¼ä¸š: {company_code}")
        if scenario_rule:
            context_parts.append(f"ğŸ¯ åˆ†æåœºæ™¯: {scenario_rule.display_name}")
            context_parts.append(f"ğŸ“Š åˆ†ææ¡†æ¶: {scenario_rule.framework}")
        context_parts.append("")

        # 2. åœºæ™¯åˆ†æè¦æ±‚
        if scenario_rule:
            context_parts.append("=== åœºæ™¯åˆ†æè¦æ±‚ ===")
            context_parts.append(f"ğŸ“ åœºæ™¯æè¿°: {scenario_rule.description}")
            context_parts.append("ğŸ” é‡ç‚¹å…³æ³¨é¢†åŸŸ:")
            for focus_area in scenario_rule.focus_areas[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                context_parts.append(f"  â€¢ {focus_area}")
            context_parts.append("")

        # 3. æœ¬åœ°æ–‡æ¡£ä¿¡æ¯
        if local_docs:
            context_parts.append("=== æœ¬åœ°æ–‡æ¡£åº“ä¿¡æ¯ ===")
            context_parts.append(f"å…±æ‰¾åˆ° {len(local_docs)} ä¸ªç›¸å…³æ–‡æ¡£")

            for i, doc in enumerate(local_docs[:3], 1):  # é™åˆ¶å‰3ä¸ª
                content = doc.get("content", "")
                source = doc.get("source", "æœªçŸ¥æ¥æº")
                similarity = doc.get("similarity", 0)
                metadata = doc.get("metadata", {})
                company = metadata.get("company", "æœªçŸ¥ä¼ä¸š")
                doc_type = metadata.get("document_type", "æœªçŸ¥ç±»å‹")

                context_parts.append(
                    f"\nã€æœ¬åœ°æ–‡æ¡£{i}ã€‘"
                    f"\nğŸ“„ æ¥æº: {source}"
                    f"\nğŸ­ ä¼ä¸š: {company}"
                    f"\nğŸ·ï¸ ç±»å‹: {doc_type}"
                    f"\nğŸ“Š ç›¸å…³åº¦: {similarity:.3f}"
                    f"\nğŸ“ å†…å®¹: {content[:250]}..."
                )
        else:
            context_parts.append("=== æœ¬åœ°æ–‡æ¡£åº“ä¿¡æ¯ ===")
            context_parts.append("âŒ æœ¬åœ°åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")
        context_parts.append("")

        # 4. ç½‘ç»œæœç´¢ç»“æœ
        if web_docs:
            context_parts.append("=== ç½‘ç»œæœ€æ–°ä¿¡æ¯ ===")
            context_parts.append(f"ğŸŒ è”ç½‘æœç´¢è·å¾— {len(web_docs)} æ¡ä¿¡æ¯")

            for i, doc in enumerate(web_docs[:2], 1):  # é™åˆ¶å‰2ä¸ª
                content = doc.get("content", "")
                metadata = doc.get("metadata", {})
                title = metadata.get("title", "ç½‘ç»œä¿¡æ¯")
                source = metadata.get("source", "ç½‘ç»œæ¥æº")
                publish_date = metadata.get("publish_date", "æœªçŸ¥æ—¥æœŸ")

                context_parts.append(
                    f"\nã€ç½‘ç»œä¿¡æ¯{i}ã€‘"
                    f"\nğŸ“° æ ‡é¢˜: {title}"
                    f"\nğŸ¢ æ¥æº: {source} ({publish_date})"
                    f"\nğŸ“ å†…å®¹: {content[:200]}..."
                )
        else:
            if web_search_info.get("performed", False):
                context_parts.append("=== ç½‘ç»œæœ€æ–°ä¿¡æ¯ ===")
                context_parts.append("âš ï¸ è”ç½‘æœç´¢æœªè·å¾—æœ‰æ•ˆç»“æœ")
            else:
                context_parts.append("=== ç½‘ç»œæœ€æ–°ä¿¡æ¯ ===")
                context_parts.append("â„¹ï¸ æœªæ‰§è¡Œè”ç½‘æœç´¢")
        context_parts.append("")

        # 5. ç»¼åˆåˆ†ææŒ‡å¯¼
        context_parts.append("=== åˆ†ææŒ‡å¯¼ ===")

        if scenario_rule:
            context_parts.append("ğŸ’¡ åœºæ™¯ç‰¹å®šåˆ†ææç¤º:")
            for req in scenario_rule.output_requirements[:3]:  # æ˜¾ç¤ºå‰3ä¸ªè¦æ±‚
                context_parts.append(f"  â€¢ {req}")
            context_parts.append("")

        total_docs = len(local_docs) + len(web_docs)
        if total_docs == 0:
            context_parts.append("ğŸš¨ è­¦å‘Š: æœªæ‰¾åˆ°ä»»ä½•ç›¸å…³ä¿¡æ¯")
            context_parts.append("è¯·åŸºäºé€šç”¨çŸ¥è¯†è¿›è¡Œåˆ†æï¼Œå¹¶æ˜ç¡®è¯´æ˜ä¿¡æ¯æ¥æºæœ‰é™")
        else:
            context_parts.append(f"âœ… å¯ç”¨ä¿¡æ¯: æœ¬åœ°{len(local_docs)}ä¸ª + ç½‘ç»œ{len(web_docs)}ä¸ª")
            context_parts.append("è¯·ç»“åˆæ‰€æœ‰å¯ç”¨ä¿¡æ¯è¿›è¡Œåˆ†æï¼Œå¹¶æ˜ç¡®åŒºåˆ†ä¿¡æ¯æ¥æº")

        return "\n".join(context_parts)

    def _build_scenario_prompt(self, query: str, context: str,
                               scenario_rule: Optional[ScenarioRule],
                               company_code: Optional[str], has_web_data: bool,
                               web_search_info: Dict) -> str:
        """æ„å»ºåœºæ™¯åŒ–æç¤ºè¯"""

        # åŸºç¡€ç³»ç»Ÿè§’è‰²
        if scenario_rule:
            system_role = f"""ä½ æ˜¯ä¸“ä¸šçš„{scenario_rule.display_name}ä¸“å®¶ï¼Œç²¾é€š{scenario_rule.framework}ã€‚
ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§åœºæ™¯è¦æ±‚è¿›è¡Œåˆ†æï¼Œç¡®ä¿åˆ†æçš„ä¸“ä¸šæ€§å’Œæ·±åº¦ã€‚"""
        else:
            system_role = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šã€ä¸¥è°¨çš„ä¼ä¸šåˆ†æä¸“å®¶ï¼Œæ“…é•¿ç»¼åˆåˆ†æå„ç§ä¿¡æ¯æºã€‚"

        # åœºæ™¯ç‰¹å®šæŒ‡å¯¼
        scenario_guidance = self._get_scenario_guidance(scenario_rule)

        # ä¿¡æ¯æ¥æºè¯´æ˜
        source_instructions = ""
        if has_web_data:
            source_instructions = f"""
    ğŸŒ ç½‘ç»œæœç´¢ä¿¡æ¯è¯´æ˜ï¼š
    - æœç´¢ç±»å‹: {web_search_info.get('search_type', 'æœªçŸ¥')}
    - æœç´¢ç½®ä¿¡åº¦: {web_search_info.get('confidence', 0):.2f}
    - è¯·ç‰¹åˆ«å…³æ³¨ç½‘ç»œä¿¡æ¯çš„æ—¶æ•ˆæ€§å’Œæƒå¨æ€§"""

        # è¾“å‡ºæ¨¡æ¿
        output_template = self._get_scenario_output_template(scenario_rule)

        # æ„å»ºå®Œæ•´æç¤ºè¯
        prompt = f"""{system_role}

## ğŸ“‹ åˆ†æä»»åŠ¡
åŸå§‹æŸ¥è¯¢ï¼š{query}
{f'ğŸ¢ ç›®æ ‡ä¼ä¸šï¼š{company_code}' if company_code else ''}
{f'ğŸ¯ åˆ†æåœºæ™¯ï¼š{scenario_rule.display_name if scenario_rule else "è‡ªå®šä¹‰åˆ†æ"}'}

## ğŸ¯ åœºæ™¯åˆ†æè¦æ±‚
{scenario_guidance}

## ğŸ“š å¯ç”¨ä¿¡æ¯æ±‡æ€»
{context}

{source_instructions}

## ğŸ“„ è¾“å‡ºæ ¼å¼è¦æ±‚
{output_template}

## âš ï¸ é‡è¦æç¤º
1. å¿…é¡»æ˜ç¡®åŒºåˆ†æœ¬åœ°æ–‡æ¡£å’Œç½‘ç»œä¿¡æ¯çš„åˆ†æä¾æ®
2. å¯¹ä¸ç¡®å®šæ€§ä¿æŒè¯šå®ï¼Œä¸å¤¸å¤§æˆ–ç¼–é€ ä¿¡æ¯
3. æ‰€æœ‰ç»“è®ºå¿…é¡»æœ‰ä¿¡æ¯æ”¯æ’‘
4. ä¿æŒä¸“ä¸šã€å®¢è§‚ã€è°¨æ…çš„åˆ†ææ€åº¦
5. ä¸¥æ ¼æŒ‰ç…§åœºæ™¯è¦æ±‚çš„åˆ†ææ¡†æ¶è¿›è¡Œåˆ†æ
"""

        return prompt

    def _get_scenario_guidance(self, scenario_rule: Optional[ScenarioRule]) -> str:
        """è·å–åœºæ™¯ç‰¹å®šæŒ‡å¯¼"""
        if not scenario_rule:
            return "è¯·åŸºäºæä¾›çš„æ‰€æœ‰ä¿¡æ¯è¿›è¡Œå…¨é¢ã€æ·±å…¥çš„åˆ†æã€‚"

        guidance_map = {
            "æ’¤å¦ä¼ä¸šåˆ†æ": f"""
ã€{scenario_rule.framework}ã€‘
è¯·æŒ‰ä»¥ä¸‹ç»´åº¦è¿›è¡Œåˆ†æï¼š

1ï¸âƒ£ ä¼ä¸šå±‚é¢ï¼š
   - è´¢åŠ¡æ•°æ®çœŸå®æ€§æ ¸æŸ¥ï¼ˆæ”¶å…¥ç¡®è®¤ã€æˆæœ¬æ ¸ç®—ã€æ¯›åˆ©ç‡å¼‚å¸¸ç­‰ï¼‰
   - å†…éƒ¨æ§åˆ¶æœ‰æ•ˆæ€§è¯„ä¼°ï¼ˆèµ„é‡‘ç®¡ç†ã€å…³è”äº¤æ˜“å†³ç­–ç­‰ï¼‰
   - æŒç»­ç»è¥èƒ½åŠ›åˆ†æï¼ˆä¸šç»©è¶‹åŠ¿ã€å®¢æˆ·ç¨³å®šæ€§ç­‰ï¼‰
   - ä¿¡æ¯æŠ«éœ²è´¨é‡æ£€æŸ¥ï¼ˆæ‹›è‚¡ä¹¦ä¸€è‡´æ€§ã€é£é™©æç¤ºç­‰ï¼‰

2ï¸âƒ£ ä¸­ä»‹æœºæ„å±‚é¢ï¼š
   - ä¿èæœºæ„æ‰§ä¸šè´¨é‡ï¼ˆå°½èŒè°ƒæŸ¥å……åˆ†æ€§ï¼‰
   - å®¡è®¡æœºæ„å·¥ä½œè´¨é‡ï¼ˆå®¡è®¡ç¨‹åºé€‚å½“æ€§ï¼‰
   - å¾‹å¸ˆæ ¸æŸ¥å……åˆ†æ€§ï¼ˆæ³•å¾‹äº‹é¡¹å®Œæ•´æ€§ï¼‰

3ï¸âƒ£ ç›‘ç®¡å®¡æ ¸å±‚é¢ï¼š
   - ç°åœºæ£€æŸ¥å‘ç°é—®é¢˜ï¼ˆä¸»è¦è¿è§„äº‹é¡¹ï¼‰
   - å®¡æ ¸é—®è¯¢é‡ç‚¹æ¼”å˜ï¼ˆç›‘ç®¡å…³æ³¨ç‚¹å˜åŒ–ï¼‰
   - æ’¤å¦åŸå› æ·±åº¦å‰–æï¼ˆç›´æ¥è§¦å‘äº‹ä»¶ï¼‰

ã€é‡ç‚¹å…³æ³¨ã€‘{', '.join(scenario_rule.focus_areas[:4])}
""",

            "é•¿æœŸè¾…å¯¼ä¼ä¸šåˆ†æ": f"""
ã€{scenario_rule.framework}ã€‘
è¯·æŒ‰ä»¥ä¸‹é˜¶æ®µè¿›è¡Œåˆ†æï¼š

1ï¸âƒ£ è¾…å¯¼è¿›åº¦è¯Šæ–­ï¼š
   - è¾…å¯¼å†ç¨‹æ—¶é—´çº¿ï¼ˆå¤‡æ¡ˆæ—¶é—´ã€å„é˜¶æ®µæƒ…å†µï¼‰
   - ä¸­ä»‹æœºæ„å˜æ›´åŠåŸå› ï¼ˆä¿èæœºæ„ã€å®¡è®¡æœºæ„ç­‰ï¼‰
   - ä¸»è¦å·¥ä½œå†…å®¹è´¨é‡è¯„ä¼°ï¼ˆè¾…å¯¼æŠ¥å‘Šã€æ•´æ”¹æƒ…å†µï¼‰

2ï¸âƒ£ éšœç¢æ·±åº¦åˆ†æï¼š
   - è´¢åŠ¡è§„èŒƒæ€§é—®é¢˜ï¼ˆä¼šè®¡æ”¿ç­–ã€æ”¶å…¥ç¡®è®¤ç­‰ï¼‰
   - æ³•å¾‹åˆè§„éšœç¢ï¼ˆè¯‰è®¼ã€å¤„ç½šã€çŸ¥è¯†äº§æƒç­‰ï¼‰
   - ä¸šåŠ¡ç‹¬ç«‹æ€§ç¼ºé™·ï¼ˆå…³è”äº¤æ˜“ã€åŒä¸šç«äº‰ç­‰ï¼‰
   - è¡Œä¸šå®šä½é—®é¢˜ï¼ˆæ¿å—åŒ¹é…åº¦ã€æ”¿ç­–æ”¯æŒåº¦ï¼‰

3ï¸âƒ£ ä¸Šå¸‚å¯è¡Œæ€§è¯„ä¼°ï¼š
   - è¿‘æœŸä¸Šå¸‚å¯èƒ½æ€§é¢„æµ‹
   - å¿…è¦æ•´æ”¹æªæ–½å»ºè®®
   - æ›¿ä»£æ–¹æ¡ˆåˆ†æï¼ˆæ–°ä¸‰æ¿ã€å¹¶è´­é‡ç»„ç­‰ï¼‰

ã€é‡ç‚¹å…³æ³¨ã€‘{', '.join(scenario_rule.focus_areas[:4])}
""",

            "ä¸Šä¸‹æ¸¸ä¼ä¸šåˆ†æ": f"""
ã€{scenario_rule.framework}ã€‘
è¯·æŒ‰ä»¥ä¸‹å±‚æ¬¡è¿›è¡Œåˆ†æï¼š

1ï¸âƒ£ è‚¡æƒå…³è”å±‚ï¼š
   - å®é™…æ§åˆ¶äººç©¿é€æ ¸æŸ¥
   - äº¤å‰æŒè‚¡å’Œä¸€è‡´è¡ŒåŠ¨å…³ç³»
   - å†å²è‚¡æƒå˜æ›´åˆè§„æ€§

2ï¸âƒ£ ä¸šåŠ¡å…³è”å±‚ï¼š
   - å…³è”äº¤æ˜“å…¬å…æ€§ï¼ˆä»·æ ¼ã€æ¡æ¬¾ã€ç»“ç®—æ–¹å¼ï¼‰
   - å®¢æˆ·ä¾›åº”å•†ä¾èµ–åº¦åˆ†æï¼ˆé›†ä¸­åº¦ã€ç¨³å®šæ€§ï¼‰
   - åŒä¸šç«äº‰è¯†åˆ«å’Œå½±å“

3ï¸âƒ£ äººå‘˜å…³è”å±‚ï¼š
   - å…³é”®äººå‘˜å…¼èŒæƒ…å†µ
   - å…±åŒæŠ•èµ„å’Œåˆ©ç›Šå…³ç³»
   - å†å²ä»»èŒå…³è”æ€§

4ï¸âƒ£ èµ„é‡‘å…³è”å±‚ï¼š
   - èµ„é‡‘å¾€æ¥å’Œæ‹…ä¿æƒ…å†µ
   - èµ„äº§ç§Ÿèµå’Œå…±äº«å®‰æ’
   - å…¶ä»–æ½œåœ¨åˆ©ç›Šè¾“é€

ã€é‡ç‚¹å…³æ³¨ã€‘{', '.join(scenario_rule.focus_areas[:4])}
"""
        }

        return guidance_map.get(scenario_rule.display_name,
                                "è¯·åŸºäºæä¾›çš„æ‰€æœ‰ä¿¡æ¯è¿›è¡Œå…¨é¢ã€æ·±å…¥çš„åˆ†æã€‚")

    # åœ¨ qwen_rag_processor.py ä¸­æ‰¾åˆ° _get_scenario_output_template æ–¹æ³•ï¼Œä¿®æ”¹å¦‚ä¸‹ï¼š

    def _get_scenario_output_template(self, scenario_rule: Optional[ScenarioRule]) -> str:
        """è·å–åœºæ™¯ç‰¹å®šçš„è¾“å‡ºæ¨¡æ¿"""

        if not scenario_rule:
            # é»˜è®¤ä½¿ç”¨æ’¤å¦ä¼ä¸šåˆ†ææ¨¡æ¿
            scenario_rule = ScenarioConfig.get_all_scenarios()[ScenarioType.WITHDRAWAL]

        # åŸºç¡€æ¨¡æ¿
        base_template = """è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼Œå¿…é¡»åŒ…å«ä»¥ä¸‹å­—æ®µï¼š{{
        "summary": "æ€»ä½“ç»“è®ºæ‘˜è¦ï¼ˆ200å­—ä»¥å†…ï¼Œæ³¨æ˜ä¸»è¦ä¿¡æ¯æ¥æºï¼‰",
        "detailed_analysis": {{
            "local_based": ["åŸºäºæœ¬åœ°æ–‡æ¡£çš„åˆ†æè¦ç‚¹1", "åŸºäºæœ¬åœ°æ–‡æ¡£çš„åˆ†æè¦ç‚¹2"],
            "web_based": ["åŸºäºç½‘ç»œä¿¡æ¯çš„åˆ†æè¦ç‚¹1", "åŸºäºç½‘ç»œä¿¡æ¯çš„åˆ†æè¦ç‚¹2"],
            "integrated": ["ç»¼åˆåˆ†æè¦ç‚¹1", "ç»¼åˆåˆ†æè¦ç‚¹2"]
        }},
        "key_findings": ["å…³é”®å‘ç°1", "å…³é”®å‘ç°2", "å…³é”®å‘ç°3"],
        "risk_assessment": {{
            "identified_risks": ["é£é™©ç‚¹1ï¼ˆæ³¨æ˜æ¥æºï¼‰", "é£é™©ç‚¹2ï¼ˆæ³¨æ˜æ¥æºï¼‰"],
            "risk_level": "é«˜/ä¸­/ä½",
            "rationale": "é£é™©è¯„ä¼°ä¾æ®"
        }},
        "recommendations": ["å…·ä½“å»ºè®®1", "å…·ä½“å»ºè®®2", "å…·ä½“å»ºè®®3"]"""

        # åœºæ™¯ç‰¹å®šå­—æ®µ
        scenario_fields = {
            "æ’¤å¦ä¼ä¸šåˆ†æ": """,
        "withdrawal_analysis": {{
            "main_reasons": ["ä¸»è¦åŸå› 1", "ä¸»è¦åŸå› 2"],
            "timeline": [{{"date": "YYYY-MM-DD", "event": "äº‹ä»¶æè¿°", "type": "ç±»å‹", "impact": "å½±å“ç¨‹åº¦"}}],
            "inquiry_focus": ["é—®è¯¢é‡ç‚¹1", "é—®è¯¢é‡ç‚¹2"],
            "reapply_prediction": "é¢„è®¡é‡æ–°ç”³æŠ¥æ—¶é—´",
            "success_probability": "é‡æ–°ä¸Šå¸‚æˆåŠŸç‡"
        }}""",

            "é•¿æœŸè¾…å¯¼ä¼ä¸šåˆ†æ": """,
        "tutoring_analysis": {{
            "start_date": "è¾…å¯¼å¼€å§‹æ—¶é—´",
            "duration_months": 0,
            "current_stage": "å½“å‰é˜¶æ®µ",
            "ipo_obstacles": [{{"type": "éšœç¢ç±»å‹", "severity": "ä¸¥é‡ç¨‹åº¦", "description": "å…·ä½“æè¿°"}}],
            "feasibility_assessment": {{
                "short_term_possibility": "è¿‘æœŸä¸Šå¸‚å¯èƒ½æ€§",
                "key_prerequisites": ["å‰ææ¡ä»¶1", "å‰ææ¡ä»¶2"]
            }}
        }}""",

            "ä¸Šä¸‹æ¸¸ä¼ä¸šåˆ†æ": """,
        "relationship_analysis": {{
            "entity_count": 0,
            "relation_count": 0,
            "relations": [{{"entity_a": "ä¼ä¸šA", "entity_b": "ä¼ä¸šB", "type": "å…³ç³»ç±»å‹", "risk_level": "é£é™©ç­‰çº§"}}],
            "independence_issues": ["ç‹¬ç«‹æ€§é—®é¢˜1", "ç‹¬ç«‹æ€§é—®é¢˜2"],
            "risk_transmission_analysis": {{"paths": [{{"from": "æºå¤´", "to": "ç›®æ ‡", "mechanism": "ä¼ å¯¼æœºåˆ¶"}}]}}
        }}"""
        }

        # æ·»åŠ åœºæ™¯ç‰¹å®šå­—æ®µ
        enhancement = scenario_fields.get(scenario_rule.display_name, "")

        # é—­åˆJSON
        closing = """
    }"""

        return base_template + enhancement + closing

    def _call_llm(self, prompt: str, model: str) -> str:
        """è°ƒç”¨é€šä¹‰åƒé—®API"""
        try:
            response = dashscope.Generation.call(
                model=model,
                prompt=prompt,
                temperature=0.2,
                top_p=0.9,
                result_format='message',
                max_tokens=5000,
                seed=12345
            )

            if response.status_code == 200:
                return response.output.choices[0].message.content
            else:
                print(f"é€šä¹‰åƒé—®APIè°ƒç”¨å¤±è´¥: {response.code} - {response.message}")
                if model != "qwen-turbo":
                    print("å°è¯•ä½¿ç”¨qwen-turboæ¨¡å‹...")
                    return self._call_llm(prompt, "qwen-turbo")
                else:
                    return f"APIè°ƒç”¨å¤±è´¥: {response.message}"

        except Exception as e:
            print(f"è°ƒç”¨LLMå¤±è´¥: {e}")
            return f"æ¨¡å‹è°ƒç”¨é”™è¯¯: {str(e)}"

    def _parse_response(self, response_text: str, scenario_rule: Optional[ScenarioRule]) -> Dict[str, Any]:
        """è§£ææ¨¡å‹å“åº”"""
        try:
            import re

            # æŸ¥æ‰¾JSONéƒ¨åˆ†
            json_match = re.search(r'\{[\s\S]*}', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                parsed = json.loads(json_str)

                # ç¡®ä¿åŒ…å«åœºæ™¯ç‰¹å®šå­—æ®µ
                if scenario_rule and scenario_rule.display_name == "æ’¤å¦ä¼ä¸šåˆ†æ":
                    if "withdrawal_analysis" not in parsed:
                        parsed["withdrawal_analysis"] = {}
                elif scenario_rule and scenario_rule.display_name == "é•¿æœŸè¾…å¯¼ä¼ä¸šåˆ†æ":
                    if "tutoring_analysis" not in parsed:
                        parsed["tutoring_analysis"] = {}
                elif scenario_rule and scenario_rule.display_name == "ä¸Šä¸‹æ¸¸ä¼ä¸šåˆ†æ":
                    if "relationship_analysis" not in parsed:
                        parsed["relationship_analysis"] = {}

                return parsed

            # å¦‚æœä¸æ˜¯æ ‡å‡†JSONï¼Œè¿”å›ç»“æ„åŒ–æ–‡æœ¬
            print("å“åº”ä¸æ˜¯æ ‡å‡†JSONæ ¼å¼")
            return self._parse_structured_response(response_text, scenario_rule)

        except json.JSONDecodeError as e:
            print(f"JSONè§£æå¤±è´¥: {e}")
            return self._create_fallback_response(response_text, scenario_rule)
        except Exception as e:
            print(f"å“åº”è§£æå¤±è´¥: {e}")
            return self._create_error_response(str(e))

    def _parse_structured_response(self, text: str, scenario_rule: Optional[ScenarioRule]) -> Dict[str, Any]:
        """è§£æç»“æ„åŒ–æ–‡æœ¬å“åº”"""
        base_response = {
            "summary": text[:300] + "..." if len(text) > 300 else text,
            "detailed_analysis": {
                "local_based": ["åŸºäºæ–‡æœ¬è§£æçš„åˆ†æ"],
                "web_based": [],
                "integrated": ["ç»¼åˆä¿¡æ¯åˆ†æ"]
            },
            "key_findings": ["å“åº”æ ¼å¼ä¸ºéæ ‡å‡†JSON"],
            "risk_assessment": {
                "identified_risks": ["æ•°æ®æ ¼å¼é£é™©"],
                "risk_level": "ä½",
                "rationale": "æ¨¡å‹å“åº”æ ¼å¼å¼‚å¸¸"
            },
            "recommendations": ["æ£€æŸ¥APIå“åº”æ ¼å¼"]
        }

        # æ·»åŠ åœºæ™¯ç‰¹å®šå­—æ®µ
        if scenario_rule and scenario_rule.display_name == "æ’¤å¦ä¼ä¸šåˆ†æ":
            base_response["withdrawal_analysis"] = {"main_reasons": ["æ ¼å¼è§£æé—®é¢˜"]}
        elif scenario_rule and scenario_rule.display_name == "é•¿æœŸè¾…å¯¼ä¼ä¸šåˆ†æ":
            base_response["tutoring_analysis"] = {"current_stage": "åˆ†æé˜¶æ®µ"}
        elif scenario_rule and scenario_rule.display_name == "ä¸Šä¸‹æ¸¸ä¼ä¸šåˆ†æ":
            base_response["relationship_analysis"] = {"relations": []}

        return base_response

    def _create_fallback_response(self, text: str, scenario_rule: Optional[ScenarioRule]) -> Dict[str, Any]:
        """åˆ›å»ºé™çº§å“åº”"""
        base_response = {
            "summary": f"åˆ†æç»“æœï¼ˆåŸå§‹å“åº”ï¼‰: {text[:200]}...",
            "detailed_analysis": {
                "local_based": ["æœ¬åœ°ä¿¡æ¯åˆ†æ"],
                "web_based": ["ç½‘ç»œä¿¡æ¯åˆ†æ"],
                "integrated": ["ç»¼åˆåˆ†æ"]
            },
            "key_findings": ["è·å–åˆ°åˆ†æç»“æœ"],
            "risk_assessment": {
                "identified_risks": ["å“åº”æ ¼å¼å¼‚å¸¸"],
                "risk_level": "ä½",
                "rationale": "ç³»ç»Ÿå¤„ç†æ­£å¸¸"
            },
            "recommendations": ["ç»§ç»­ç›‘æ§ä¼ä¸šåŠ¨æ€"]
        }

        # æ·»åŠ åœºæ™¯ç‰¹å®šå­—æ®µ
        if scenario_rule:
            base_response["information_quality"] = {
                "source_reliability": "ä¸­",
                "data_completeness": "ä¸€èˆ¬",
                "timeliness": "æœ€æ–°",
                "limitations": ["å“åº”æ ¼å¼éœ€ä¼˜åŒ–"]
            }

        return base_response

    def _create_error_response(self, error: str) -> Dict[str, Any]:
        """åˆ›å»ºé”™è¯¯å“åº”"""
        return {
            "summary": f"åˆ†æè¿‡ç¨‹ä¸­é‡åˆ°é”™è¯¯: {error}",
            "detailed_analysis": {
                "local_based": ["ç³»ç»Ÿå¤„ç†å¼‚å¸¸"],
                "web_based": [],
                "integrated": []
            },
            "key_findings": ["ç³»ç»Ÿæš‚æ—¶ä¸å¯ç”¨"],
            "risk_assessment": {
                "identified_risks": ["ç³»ç»Ÿé”™è¯¯"],
                "risk_level": "é«˜",
                "rationale": "æŠ€æœ¯æ•…éšœ"
            },
            "recommendations": ["è”ç³»æŠ€æœ¯æ”¯æŒ", "ç¨åé‡è¯•"]
        }

    def _enhance_response(self, response: Dict[str, Any],
                          local_docs: List[Dict],
                          web_docs: List[Dict],
                          web_search_info: Dict,
                          scenario_rule: Optional[ScenarioRule]) -> Dict[str, Any]:
        """å¢å¼ºå“åº”ä¿¡æ¯"""
        # æ·»åŠ ä¿¡æ¯æ¥æºç»Ÿè®¡
        response["source_statistics"] = {
            "local_documents": len(local_docs),
            "web_results": len(web_docs),
            "total_sources": len(local_docs) + len(web_docs),
            "web_search_performed": web_search_info.get("performed", False),
            "web_search_confidence": web_search_info.get("confidence", 0.0)
        }

        # æ·»åŠ åœºæ™¯ä¿¡æ¯
        if scenario_rule:
            response["scenario_info"] = {
                "name": scenario_rule.display_name,
                "framework": scenario_rule.framework,
                "focus_areas": scenario_rule.focus_areas[:5]  # å–å‰5ä¸ª
            }

        # æ·»åŠ æ—¶é—´æˆ³
        response["analysis_timestamp"] = datetime.now().isoformat()

        return response

    def _build_comprehensive_result(self, query: str, response: Dict,
                                    local_docs: List[Dict], web_docs: List[Dict],
                                    web_search_analysis: Dict, processing_time: float,
                                    scenario_name: str, company_code: Optional[str],
                                    threshold: float, web_mode: str) -> Dict[str, Any]:
        """æ„å»ºå…¨é¢çš„ç»“æœ"""
        return {
            "query": query,
            "response": response,
            "retrieval_stats": {
                "local_documents": len(local_docs),
                "web_results": len(web_docs),
                "total_sources": len(local_docs) + len(web_docs),
                "similarity_threshold": threshold
            },
            "source_documents": local_docs + web_docs,
            "processing_time": round(processing_time, 2),
            "scenario_name": scenario_name,
            "company_code": company_code,
            "timestamp": datetime.now().isoformat(),
            "web_mode": web_mode,
            "web_search_info": web_search_analysis
        }

    def _build_error_result(self, query: str, scenario: Optional[str],
                            company_code: Optional[str], error: str) -> Dict[str, Any]:
        """æ„å»ºé”™è¯¯ç»“æœ"""
        return {
            "query": query,
            "response": self._create_error_response(error),
            "retrieval_stats": {
                "local_documents": 0,
                "web_results": 0,
                "total_sources": 0,
                "error": error
            },
            "source_documents": [],
            "processing_time": 0,
            "scenario_name": scenario or "è‡ªå®šä¹‰åˆ†æ",
            "company_code": company_code,
            "timestamp": datetime.now().isoformat(),
            "web_mode": "none",
            "error": error
        }

    def clear_all_caches(self):
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        if self.web_searcher:
            self.web_searcher.clear_cache()
        print("æ‰€æœ‰ç¼“å­˜å·²æ¸…ç©º")

    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        return {
            "rag_processor": "è¿è¡Œä¸­",
            "web_search_enabled": self.web_search_enabled,
            "model": self.model,
            "scenario_support": True,
            "version": "3.0"
        }