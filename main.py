# soure/main.py
import tempfile
from typing import Dict, List, Optional
import streamlit as st
import pandas as pd
from datetime import datetime
import json
import sys
import os
import yaml
import hashlib
import time

from matplotlib import pyplot as plt
from soure.document.document_processor import PDFProcessor
from soure.llm.intel_extractor import LLMExtractor
from soure.llm.scenario_config import ScenarioConfig, ScenarioType, ScenarioRule

sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from soure.embedding.vectorizer_qwen import QwenVectorizer
from soure.rag.qwen_rag_processor import QwenRAGProcessor


st.set_page_config(
    page_title="ä¼ä¸šæ™ºèƒ½åˆ†æåŠ©æ‰‹",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# åˆå§‹åŒ–èŠå¤©å†å²
if "messages" not in st.session_state:
    st.session_state.messages = []

if "analysis_history" not in st.session_state:
    st.session_state.analysis_history = []

if "uploaded_files" not in st.session_state:
    st.session_state.uploaded_files = []

if "message_counter" not in st.session_state:
    st.session_state.message_counter = 0


def generate_unique_key(prefix: str, data: Optional[Dict] = None) -> str:
    """ç”Ÿæˆå”¯ä¸€çš„key"""
    st.session_state.message_counter += 1
    counter = st.session_state.message_counter

    if data:
        timestamp = data.get("timestamp", str(time.time()))
        query = data.get("query", "")
        key_str = f"{prefix}_{timestamp}_{query}_{counter}"
    else:
        key_str = f"{prefix}_{time.time()}_{counter}"

    return f"{prefix}_{hashlib.md5(key_str.encode()).hexdigest()[:8]}"


@st.cache_resource
def init_system():
    """åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶"""
    try:
        with open("config/config.yaml", 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)

        api_key = "sk-6892cc65b78941e7a6981cae25997c0b"
        if not api_key:
            st.error("è¯·è®¾ç½®DASHSCOPE_API_KEYç¯å¢ƒå˜é‡æˆ–Streamlit secrets")
            st.stop()

        vectorizer = QwenVectorizer(config)
        rag_processor = QwenRAGProcessor(
            vectorizer=vectorizer,
            api_key=api_key,
            model=config['llm'].get('model', 'qwen-max')
        )

        # åˆå§‹åŒ–å¤§æ¨¡å‹è¯†åˆ«å™¨
        llm_extractor = LLMExtractor(api_key)

        return {
            "config": config,
            "vectorizer": vectorizer,
            "rag_processor": rag_processor,
            "llm_extractor": llm_extractor,  # æ›¿æ¢ä¸ºæ–°çš„è¯†åˆ«å™¨
            "api_key": api_key
        }
    except Exception as e:
        st.error(f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        st.stop()


def add_message(role: str, content: str, analysis_result: Optional[Dict] = None):
    """æ·»åŠ æ¶ˆæ¯åˆ°èŠå¤©å†å²"""
    if analysis_result:
        analysis_result["unique_id"] = generate_unique_key("analysis", {
            "timestamp": analysis_result.get("timestamp", str(datetime.now().timestamp())),
            "query": analysis_result.get("query", "")
        })

    message_id = generate_unique_key("msg", {"content": content, "role": role})

    st.session_state.messages.append({
        "role": role,
        "content": content,
        "timestamp": datetime.now().isoformat(),
        "analysis_result": analysis_result,
        "unique_id": message_id
    })

    if analysis_result:
        st.session_state.analysis_history.append(analysis_result)


def display_message(message: Dict):
    """æ˜¾ç¤ºå•æ¡æ¶ˆæ¯"""
    role = message["role"]
    content = message["content"]
    analysis_result = message.get("analysis_result")
    message_id = message.get("unique_id", "")

    with st.chat_message(role):
        st.markdown(content)

        if analysis_result and role == "assistant":
            display_analysis_details(analysis_result, message_id)


def display_scenario_specific_analysis(response: Dict, scenario_rule: ScenarioRule, company_code: str):
    """æ ¹æ®åœºæ™¯æ˜¾ç¤ºç‰¹å®šçš„åˆ†æå†…å®¹"""

    # æ˜¾ç¤ºåœºæ™¯æ ‡é¢˜å’Œæ¡†æ¶
    st.subheader(f"{scenario_rule.icon} {scenario_rule.display_name}")
    st.caption(f"åˆ†ææ¡†æ¶: {scenario_rule.framework}")

    # åˆ›å»ºåœºæ™¯ç‰¹å®šç»„ä»¶
    create_scenario_specific_components(scenario_rule, response, company_code)


    # æ˜¾ç¤ºè¯¦ç»†åˆ†æå†…å®¹
    st.subheader("è¯¦ç»†åˆ†æå†…å®¹")

    # æœ¬åœ°æ–‡æ¡£åˆ†æ
    detailed_analysis = response.get("detailed_analysis", {})
    if detailed_analysis and isinstance(detailed_analysis, dict):
        local_based = detailed_analysis.get("local_based", [])
        if local_based and isinstance(local_based, list):
            with st.expander("åŸºäºæœ¬åœ°æ–‡æ¡£çš„åˆ†æ", expanded=False):
                for i, item in enumerate(local_based):
                    if isinstance(item, str):
                        st.markdown(f"**{i + 1}.** {item}")

        # ç½‘ç»œä¿¡æ¯åˆ†æ
        web_based = detailed_analysis.get("web_based", [])
        if web_based and isinstance(web_based, list):
            with st.expander("åŸºäºç½‘ç»œä¿¡æ¯çš„åˆ†æ", expanded=False):
                for i, item in enumerate(web_based):
                    if isinstance(item, str):
                        st.markdown(f"**{i + 1}.** {item}")

        # ç»¼åˆåˆ†æ
        integrated = detailed_analysis.get("integrated", [])
        if integrated and isinstance(integrated, list):
            with st.expander("ç»¼åˆåˆ†æç»“è®º", expanded=False):
                for i, item in enumerate(integrated):
                    if isinstance(item, str):
                        st.markdown(f"**{i + 1}.** {item}")
    else:
        analysis_list = response.get("analysis", [])
        if analysis_list and isinstance(analysis_list, list):
            with st.expander("åˆ†æè¦ç‚¹", expanded=False):
                for i, item in enumerate(analysis_list):
                    if isinstance(item, str):
                        st.markdown(f"**{i + 1}.** {item}")
        else:
            st.info("æš‚æ— è¯¦ç»†åˆ†æå†…å®¹")


def display_analysis_details(result: Dict, message_id: str = ""):
    """æ˜¾ç¤ºåˆ†æç»“æœçš„è¯¦ç»†ä¿¡æ¯"""
    if not isinstance(result, dict):
        st.warning("åˆ†æç»“æœæ ¼å¼å¼‚å¸¸")
        return

    # ç”Ÿæˆå”¯ä¸€key
    unique_key = result.get("unique_id", message_id)
    if not unique_key:
        unique_key = generate_unique_key("analysis", result)

    response = result.get("response", {})
    retrieval_stats = result.get("retrieval_stats", {})
    scenario_name = result.get("scenario_name", "è‡ªå®šä¹‰åˆ†æ")
    company_code = result.get("company_code", "æœªè¯†åˆ«åˆ°ä¼ä¸š")

    # è·å–åœºæ™¯è§„åˆ™
    scenario_rule = ScenarioConfig.get_scenario_by_name(scenario_name)
    if not scenario_rule:
        # å¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°åœºæ™¯ï¼Œä½¿ç”¨æ’¤å¦ä¼ä¸šåˆ†æä½œä¸ºé»˜è®¤
        scenario_rule = ScenarioConfig.get_default_scenario()
        scenario_name = scenario_rule.display_name

    # åˆ›å»ºå¯æŠ˜å çš„è¯¦ç»†ä¿¡æ¯åŒºåŸŸ
    with st.expander("æŸ¥çœ‹åˆ†æè¯¦æƒ…", expanded=False):
        if response and isinstance(response, dict):
            display_scenario_specific_analysis(response, scenario_rule, company_code)

            st.divider()

            # ä¼ä¸šé£é™©æç¤º
            st.subheader("ä¼ä¸šé£é™©æç¤º")
            risk_assessment = response.get("risk_assessment", {})

            if risk_assessment and isinstance(risk_assessment, dict):
                identified_risks = risk_assessment.get("identified_risks", [])
                risk_level = risk_assessment.get("risk_level", "æœªçŸ¥")
                rationale = risk_assessment.get("rationale", "")

                col1, col2 = st.columns([1, 3])
                with col1:
                    risk_color = {
                        "é«˜": "ğŸ”´",
                        "ä¸­": "ğŸŸ¡",
                        "ä½": "ğŸŸ¢",
                        "æœªçŸ¥": "âšª"
                    }
                    risk_icon = risk_color.get(risk_level, "âšª")
                    st.metric("é£é™©çº§åˆ«", f"{risk_icon} {risk_level}")

                with col2:
                    if rationale:
                        st.caption(f"é£é™©è¯„ä¼°ä¾æ®: {rationale}")

                if identified_risks and isinstance(identified_risks, list):
                    with st.expander(f"å…·ä½“é£é™©ç‚¹ ({len(identified_risks)}ä¸ª)", expanded=True):
                        for i, risk in enumerate(identified_risks):
                            if isinstance(risk, str):
                                st.warning(f"**â€¢ é£é™©{i + 1}:** {risk}")
                else:
                    st.info("æš‚æ— å…·ä½“é£é™©ä¿¡æ¯")
            else:
                risks_list = response.get("risks", [])
                if risks_list and isinstance(risks_list, list):
                    for i, risk in enumerate(risks_list):
                        if isinstance(risk, str):
                            st.warning(f"**â€¢ é£é™©{i + 1}:** {risk}")
                else:
                    st.info("æš‚æ— é£é™©æç¤º")

        st.divider()

        # å‚è€ƒæ–‡æ¡£
        source_docs = result.get("source_documents", [])
        if source_docs and isinstance(source_docs, list):
            with st.expander(f"å‚è€ƒæ–‡æ¡£ ({len(source_docs)}ä¸ª)", expanded=False):
                for i, doc in enumerate(source_docs):
                    doc_title = "æœªçŸ¥æ–‡æ¡£"
                    doc_content = "æ— å†…å®¹é¢„è§ˆ"
                    doc_source = "æœªçŸ¥æ¥æº"

                    if isinstance(doc, dict):
                        doc_title = doc.get('title', doc.get('source', 'æœªçŸ¥æ–‡æ¡£'))
                        doc_content = doc.get('content_preview', doc.get('content', 'æ— é¢„è§ˆå†…å®¹'))
                        doc_source = doc.get('source', 'æœªçŸ¥æ¥æº')
                    elif isinstance(doc, str):
                        doc_title = f"æ–‡æ¡£ {i + 1}"
                        doc_content = doc[:200] + "..." if len(doc) > 200 else doc
                        doc_source = "æ–‡æœ¬å†…å®¹"

                    with st.expander(f"{doc_title}", expanded=False):
                        st.caption(f"**æ¥æº:** {doc_source}")
                        st.write(doc_content)
        else:
            st.info("æš‚æ— å‚è€ƒæ–‡æ¡£")

        # æ“ä½œæŒ‰é’®
        st.divider()
        col1, col2 = st.columns(2)
        with col1:
            export_key = f"export_{unique_key}"
            if st.button("å¯¼å‡ºæŠ¥å‘Š", key=export_key, width='stretch'):
                report = {
                    "ç”Ÿæˆæ—¶é—´": result.get("timestamp", datetime.now().isoformat()),
                    "åˆ†æåœºæ™¯": scenario_rule.display_name,
                    "ç›®æ ‡ä¼ä¸š": result.get("company_code"),
                    "æŸ¥è¯¢å†…å®¹": result.get("query"),
                    "åˆ†æç»“æœ": result.get("response", {}),
                    "æ£€ç´¢ç»Ÿè®¡": result.get("retrieval_stats", {}),
                    "å‚è€ƒæ–‡æ¡£": result.get("source_documents", [])
                }
                st.download_button(
                    label="ä¸‹è½½JSONæŠ¥å‘Š",
                    data=json.dumps(report, ensure_ascii=False, indent=2),
                    file_name=f"ä¼ä¸šåˆ†ææŠ¥å‘Š_{company_code or 'æœªçŸ¥ä¼ä¸š'}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime="application/json",
                    key=f"download_{unique_key}"
                )

def clear_chat_history():
    """æ¸…ç©ºèŠå¤©å†å²"""
    st.session_state.messages = []
    st.session_state.analysis_history = []
    st.success("èŠå¤©è®°å½•å·²æ¸…ç©º")


def create_scenario_specific_components(scenario_rule: ScenarioRule, response: Dict, company_code: str):
    """åˆ›å»ºåœºæ™¯ç‰¹å®šçš„å±•ç¤ºç»„ä»¶"""

    scenario_name = scenario_rule.display_name

    # æ ¹æ®åœºæ™¯åç§°é€‰æ‹©ç»„ä»¶
    if scenario_name == "æ’¤å¦ä¼ä¸šåˆ†æ":
        create_withdrawal_analysis_components(response, scenario_rule, company_code)
    elif scenario_name == "é•¿æœŸè¾…å¯¼ä¼ä¸šåˆ†æ":
        create_tutoring_analysis_components(response, scenario_rule, company_code)
    elif scenario_name == "ä¸Šä¸‹æ¸¸ä¼ä¸šåˆ†æ":
        create_relationship_analysis_components(response, scenario_rule, company_code)


def create_withdrawal_analysis_components(response: Dict, scenario_rule: ScenarioRule, company_code: str):
    """åˆ›å»ºæ’¤å¦ä¼ä¸šåˆ†æä¸“ç”¨ç»„ä»¶"""

    # 1. æ’¤å¦é£é™©ä»ªè¡¨ç›˜
    st.subheader("æ’¤å¦é£é™©ç»¼åˆè¯„ä¼°")

    risk_assessment = response.get("risk_assessment", {})
    withdrawal_analysis = response.get("withdrawal_analysis", {})

    col1, col2, col3 = st.columns(3)
    with col1:
        risk_level = risk_assessment.get("risk_level", "æœªçŸ¥")
        risk_config = {
            "é«˜": {"color": "ğŸ”´", "desc": "å­˜åœ¨é‡å¤§å®¡æ ¸éšœç¢"},
            "ä¸­": {"color": "ğŸŸ¡", "desc": "éƒ¨åˆ†é—®é¢˜éœ€é‡ç‚¹æ•´æ”¹"},
            "ä½": {"color": "ğŸŸ¢", "desc": "é—®é¢˜ç›¸å¯¹å¯æ§"},
            "æœªçŸ¥": {"color": "âšª", "desc": "ä¿¡æ¯ä¸è¶³æ— æ³•è¯„ä¼°"}
        }
        config = risk_config.get(risk_level, risk_config["æœªçŸ¥"])
        st.metric("æ’¤å¦é£é™©ç­‰çº§", f"{config['color']} {risk_level}")
        st.caption(config['desc'])

    with col2:
        risks = risk_assessment.get("identified_risks", [])
        if isinstance(risks, list):
            st.metric("ä¸»è¦é—®é¢˜æ•°é‡", len(risks))
        else:
            st.metric("ä¸»è¦é—®é¢˜æ•°é‡", 0)


    # 2. æ’¤å¦åŸå› æ—¶é—´çº¿
    st.subheader("æ’¤å¦å…³é”®äº‹ä»¶æ—¶é—´çº¿")

    timeline_data = withdrawal_analysis.get("timeline", [])
    if timeline_data and isinstance(timeline_data, list):
        for event in timeline_data:
            if isinstance(event, dict):
                with st.expander(f"{event.get('date', 'æœªçŸ¥æ—¥æœŸ')} - {event.get('event', 'æœªçŸ¥äº‹ä»¶')}"):
                    st.write(f"**äº‹ä»¶ç±»å‹**: {event.get('type', 'æœªçŸ¥')}")
                    st.write(f"**å½±å“ç¨‹åº¦**: {event.get('impact', 'æœªçŸ¥')}")
                    if event.get('description'):
                        st.write(f"**è¯¦ç»†æè¿°**: {event['description']}")
            elif isinstance(event, str):
                st.info(f"â€¢ {event}")
    else:
        st.info("æš‚æ— è¯¦ç»†æ—¶é—´çº¿ä¿¡æ¯")

    # 3. å®¡æ ¸é—®è¯¢é‡ç‚¹åˆ†æ
    st.subheader("å®¡æ ¸é—®è¯¢é‡ç‚¹åˆ†æ")

    inquiry_analysis = withdrawal_analysis.get("inquiry_analysis", {})
    if inquiry_analysis and isinstance(inquiry_analysis, dict):
        rounds = inquiry_analysis.get("inquiry_rounds", [])

        if rounds and isinstance(rounds, list):
            for i, round_data in enumerate(rounds):
                if isinstance(round_data, dict):
                    with st.expander(f"ç¬¬{round_data.get('round_number', i + 1)}è½®é—®è¯¢ ({round_data.get('date', '')})",
                                     expanded=i == 0):
                        col_a, col_b = st.columns(2)
                        with col_a:
                            st.write(f"**é—®é¢˜æ•°é‡**: {round_data.get('question_count', 0)}")

                            focus_areas = round_data.get('focus_areas', [])
                            if isinstance(focus_areas, list):
                                st.write(f"**é‡ç‚¹é¢†åŸŸ**: {', '.join(focus_areas)}")
                            else:
                                st.write(f"**é‡ç‚¹é¢†åŸŸ**: {focus_areas}")

                        with col_b:
                            st.write(f"**å›å¤è´¨é‡**: {round_data.get('reply_quality', 'æœªçŸ¥')}")
                            st.write(f"**æ•´æ”¹æƒ…å†µ**: {round_data.get('rectification', 'æœªçŸ¥')}")

                        key_questions = round_data.get('key_questions', [])
                        if key_questions and isinstance(key_questions, list):
                            st.write("**å…³é”®é—®é¢˜**:")
                            for q in key_questions:
                                if isinstance(q, str):
                                    st.write(f"â€¢ {q}")
                elif isinstance(round_data, str):
                    st.info(f"â€¢ é—®è¯¢è½®æ¬¡ {i + 1}: {round_data}")
    else:
        st.info("æš‚æ— å®¡æ ¸é—®è¯¢åˆ†ææ•°æ®")

    # 4. æ•´æ”¹å»ºè®®ä¸é‡æ–°ä¸Šå¸‚è·¯å¾„
    st.subheader("æ•´æ”¹å»ºè®®ä¸é‡æ–°ä¸Šå¸‚è·¯å¾„")

    recommendations = response.get("recommendations", [])
    if recommendations and isinstance(recommendations, list):
        tab1, tab2, tab3 = st.tabs(["ç«‹å³æ•´æ”¹é¡¹", "ä¸­æœŸæ”¹è¿›é¡¹", "é•¿æœŸä¼˜åŒ–é¡¹"])

        with tab1:
            urgent_items = [r for r in recommendations if isinstance(r, dict) and r.get('priority') == 'urgent']
            if urgent_items:
                for item in urgent_items:
                    st.warning(f"**{item.get('title', '')}**")
                    st.write(item.get('description', ''))
                    st.write(f"*é¢„è®¡è€—æ—¶: {item.get('duration', 'æœªçŸ¥')}*")
            else:
                st.info("æ— ç«‹å³æ•´æ”¹é¡¹")

        with tab2:
            medium_items = [r for r in recommendations if isinstance(r, dict) and r.get('priority') == 'medium']
            if medium_items:
                for item in medium_items:
                    st.info(f"**{item.get('title', '')}**")
                    st.write(item.get('description', ''))
                    st.write(f"*é¢„è®¡è€—æ—¶: {item.get('duration', 'æœªçŸ¥')}*")
            else:
                st.info("æ— ä¸­æœŸæ”¹è¿›é¡¹")

        with tab3:
            long_items = [r for r in recommendations if isinstance(r, dict) and r.get('priority') == 'long']
            if long_items:
                for item in long_items:
                    st.success(f"**{item.get('title', '')}**")
                    st.write(item.get('description', ''))
                    st.write(f"*é¢„è®¡è€—æ—¶: {item.get('duration', 'æœªçŸ¥')}*")
            else:
                st.info("æ— é•¿æœŸä¼˜åŒ–é¡¹")
    else:
        st.info("æš‚æ— æ•´æ”¹å»ºè®®")
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        st.write("**è°ƒè¯•ä¿¡æ¯**: ")
        st.write(f"- recommendationså­—æ®µç±»å‹: {type(recommendations)}")
        st.write(f"- recommendationså†…å®¹: {recommendations}")
        # æ˜¾ç¤ºæ•´ä¸ªresponseç»“æ„çš„ä¸€éƒ¨åˆ†ç”¨äºè°ƒè¯•
        st.write(f"- responseä¸­åŒ…å«çš„é”®: {list(response.keys())}")


# ä¿®æ”¹ create_tutoring_analysis_components å‡½æ•°ä¸­çš„ç›¸å…³éƒ¨åˆ†ï¼š

def create_tutoring_analysis_components(response: Dict, scenario_rule: ScenarioRule, company_code: str):
    """åˆ›å»ºé•¿æœŸè¾…å¯¼ä¼ä¸šåˆ†æä¸“ç”¨ç»„ä»¶"""

    # 1. è¾…å¯¼å†ç¨‹æ¦‚è§ˆ
    st.subheader("è¾…å¯¼å†ç¨‹æ¦‚è§ˆ")

    tutoring_analysis = response.get("tutoring_analysis", {})

    col1, col2, col3 = st.columns(3)
    with col1:
        start_date = tutoring_analysis.get('start_date', 'æœªçŸ¥')
        st.metric("è¾…å¯¼å¼€å§‹æ—¶é—´", start_date)

    with col2:
        duration = tutoring_analysis.get('duration_months', 0)
        st.metric("è¾…å¯¼æ—¶é•¿(æœˆ)", duration)

    with col3:
        stage = tutoring_analysis.get('current_stage', 'æœªçŸ¥')
        st.metric("å½“å‰é˜¶æ®µ", stage)

    # 2. è¾…å¯¼é˜¶æ®µæ—¶é—´çº¿
    st.subheader("è¾…å¯¼é˜¶æ®µåˆ†æ")

    stages = tutoring_analysis.get('stages', [])
    if stages and isinstance(stages, list):
        for stage in stages:
            if isinstance(stage, dict):
                status_icon = "âœ…" if stage.get('completed') else "â³"
                with st.expander(f"{status_icon} {stage.get('name', 'æœªçŸ¥é˜¶æ®µ')} ({stage.get('date_range', '')})"):
                    st.write(f"**ä¸»è¦å†…å®¹**: {stage.get('content', '')}")
                    st.write(f"**å®Œæˆæƒ…å†µ**: {'å·²å®Œæˆ' if stage.get('completed') else 'è¿›è¡Œä¸­/æœªå¼€å§‹'}")

                    issues = stage.get('issues', [])
                    if issues and isinstance(issues, list):
                        st.write("**å­˜åœ¨é—®é¢˜**:")
                        for issue in issues:
                            if isinstance(issue, str):
                                st.warning(f"â€¢ {issue}")
            elif isinstance(stage, str):
                st.info(f"â€¢ {stage}")
    else:
        st.info("æš‚æ— è¾…å¯¼é˜¶æ®µä¿¡æ¯")

    # 3. ä¸Šå¸‚éšœç¢åˆ†æ
    st.subheader("ä¸»è¦ä¸Šå¸‚éšœç¢åˆ†æ")

    obstacles = tutoring_analysis.get("ipo_obstacles", [])
    if obstacles and isinstance(obstacles, list):
        obstacle_data = []
        for obs in obstacles:
            if isinstance(obs, dict):
                obstacle_data.append({
                    "éšœç¢ç±»å‹": obs.get('type', ''),
                    "ä¸¥é‡ç¨‹åº¦": obs.get('severity', ''),
                    "å½±å“ç¯èŠ‚": obs.get('impact_stage', ''),
                    "æ•´æ”¹éš¾åº¦": obs.get('rectification_difficulty', '')
                })

        if obstacle_data:
            obstacle_df = pd.DataFrame(obstacle_data)
            st.dataframe(obstacle_df, width='stretch')

            # éšœç¢ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ
            severity_counts = obstacle_df['ä¸¥é‡ç¨‹åº¦'].value_counts()
            if not severity_counts.empty:
                fig, ax = plt.subplots()
                severity_counts.plot(kind='bar', ax=ax, color=['#ff6b6b', '#ffa726', '#66bb6a'])
                ax.set_ylabel('éšœç¢æ•°é‡')
                ax.set_title('ä¸Šå¸‚éšœç¢ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ')
                st.pyplot(fig)
        else:
            st.info("æš‚æ— æœ‰æ•ˆçš„éšœç¢æ•°æ®")
    else:
        st.info("æš‚æ— ä¸Šå¸‚éšœç¢åˆ†æ")

# soure/main.py
# ä¿®æ”¹ create_relationship_analysis_components å‡½æ•°ä¸­çš„ç›¸å…³éƒ¨åˆ†ï¼š

def create_relationship_analysis_components(response: Dict, scenario_rule: ScenarioRule, company_code: str):
    """åˆ›å»ºä¸Šä¸‹æ¸¸ä¼ä¸šåˆ†æä¸“ç”¨ç»„ä»¶"""

    # 1. å…³è”ç½‘ç»œæ¦‚è§ˆ
    st.subheader("ğŸ”— å…³è”ç½‘ç»œæ¦‚è§ˆ")

    relationship_analysis = response.get("relationship_analysis", {})

    col1, col2, col3 = st.columns(3)
    with col1:
        entity_count = relationship_analysis.get('entity_count', 0)
        st.metric("å…³è”å®ä½“æ•°é‡", entity_count)

    with col2:
        relation_count = relationship_analysis.get('relation_count', 0)
        st.metric("å…³è”å…³ç³»æ•°é‡", relation_count)

    with col3:
        core_entities = relationship_analysis.get('core_entities', 0)
        st.metric("æ ¸å¿ƒå…³è”å®ä½“", core_entities)

    # 2. å…³è”å…³ç³»çŸ©é˜µ
    relations = relationship_analysis.get('relations', [])
    if relations:
        relation_data = []
        for rel in relations:
            # å®‰å…¨å¤„ç†ï¼šç¡®ä¿relæ˜¯å­—å…¸
            if isinstance(rel, dict):
                relation_data.append({
                    "å…³è”æ–¹A": rel.get('entity_a', ''),
                    "å…³è”æ–¹B": rel.get('entity_b', ''),
                    "å…³ç³»ç±»å‹": rel.get('relation_type', ''),
                    "äº¤æ˜“é‡‘é¢": rel.get('transaction_amount', 'N/A'),
                    "æ¯”ä¾‹(%)": rel.get('percentage', 'N/A'),
                    "å…¬å…æ€§": rel.get('fairness', 'æœªçŸ¥')
                })
            elif isinstance(rel, str):
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç®€å•æ˜¾ç¤º
                relation_data.append({
                    "å…³è”å…³ç³»": rel
                })

        if relation_data:
            relation_df = pd.DataFrame(relation_data)
            st.dataframe(relation_df, width='stretch')
        else:
            st.info("æš‚æ— æœ‰æ•ˆçš„å…³è”å…³ç³»æ•°æ®")

    # 3. é£é™©ä¼ å¯¼åˆ†æ
    st.subheader("å…³è”é£é™©ä¼ å¯¼åˆ†æ")

    risk_transmission = relationship_analysis.get("risk_transmission_analysis", {})
    if risk_transmission and isinstance(risk_transmission, dict):
        transmission_paths = risk_transmission.get('paths', [])

        if transmission_paths and isinstance(transmission_paths, list):
            for path in transmission_paths:
                if isinstance(path, dict):
                    with st.expander(f"é£é™©ä¼ å¯¼è·¯å¾„: {path.get('from', '')} â†’ {path.get('to', '')}"):
                        st.write(f"**ä¼ å¯¼æœºåˆ¶**: {path.get('mechanism', '')}")
                        st.write(f"**å½±å“ç¨‹åº¦**: {path.get('impact_level', '')}")
                        st.write(f"**å‘ç”Ÿæ¦‚ç‡**: {path.get('probability', '')}")

                        if path.get('mitigation_measures'):
                            st.write("**é˜²èŒƒæªæ–½**:")
                            for measure in path.get('mitigation_measures', []):
                                st.info(f"â€¢ {measure}")
                elif isinstance(path, str):
                    st.info(f"â€¢ {path}")
        else:
            st.info("æš‚æ— é£é™©ä¼ å¯¼è·¯å¾„ä¿¡æ¯")
    else:
        st.info("æš‚æ— é£é™©ä¼ å¯¼åˆ†ææ•°æ®")

    # 4. ç‹¬ç«‹æ€§æ•´æ”¹å»ºè®® - ä¿®å¤è¿™é‡Œçš„é”™è¯¯
    st.subheader("ç‹¬ç«‹æ€§æ•´æ”¹å»ºè®®")

    independence_issues = relationship_analysis.get("independence_issues", [])
    if independence_issues and isinstance(independence_issues, list):
        for i, issue in enumerate(independence_issues):
            if isinstance(issue, dict):
                # ä½¿ç”¨å®‰å…¨çš„getæ–¹æ³•ï¼Œæä¾›é»˜è®¤å€¼
                issue_type = issue.get('type', f'ç‹¬ç«‹æ€§é—®é¢˜{i + 1}')
                severity = issue.get('severity', 'æœªçŸ¥')

                with st.expander(f"{issue_type} - ä¸¥é‡ç¨‹åº¦: {severity}"):
                    st.write(f"**é—®é¢˜æè¿°**: {issue.get('description', '')}")
                    st.write(f"**å½±å“åˆ†æ**: {issue.get('impact_analysis', '')}")

                    suggestions = issue.get('rectification_suggestions', [])
                    if suggestions and isinstance(suggestions, list):
                        st.write("**æ•´æ”¹å»ºè®®**:")
                        for suggestion in suggestions:
                            if isinstance(suggestion, str):
                                st.success(f"â€¢ {suggestion}")
                    elif isinstance(suggestions, str):
                        st.success(f"â€¢ {suggestions}")
            elif isinstance(issue, str):
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥æ˜¾ç¤º
                with st.expander(f"ç‹¬ç«‹æ€§é—®é¢˜ {i + 1}"):
                    st.write(f"**é—®é¢˜**: {issue}")
    else:
        st.info("æš‚æ— ç‹¬ç«‹æ€§æ•´æ”¹å»ºè®®")


def create_default_analysis_components(response: Dict, scenario_rule: ScenarioRule, company_code: str):
    """åˆ›å»ºé»˜è®¤åˆ†æç»„ä»¶"""

    st.subheader("ç»¼åˆåˆ†ææ¦‚è§ˆ")

    # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
    key_metrics = response.get("key_metrics", {})
    if key_metrics:
        cols = st.columns(min(4, len(key_metrics)))
        for idx, (metric_name, metric_value) in enumerate(key_metrics.items()):
            with cols[idx % len(cols)]:
                st.metric(metric_name, metric_value)


def main():
    # ========== ä¾§è¾¹æ  ==========
    with st.sidebar:
        st.title("âš™ï¸ æ–‡æ¡£ç®¡ç†")

        # æ–‡æ¡£ç®¡ç†
        st.subheader("ä¸Šä¼ ä¼ä¸šæ–‡æ¡£")

        uploaded_files = st.file_uploader(
            "é€‰æ‹©PDFæ–‡æ¡£",
            type=['pdf'],
            accept_multiple_files=True,
            help="ä¸Šä¼ ä¼ä¸šç›¸å…³PDFæ–‡æ¡£ï¼Œæ”¯æŒå¤šæ–‡ä»¶ä¸Šä¼ "
        )

        if uploaded_files:
            st.session_state.uploaded_files = uploaded_files
            with st.expander(f"å·²ä¸Šä¼  ({len(uploaded_files)}ä¸ªæ–‡ä»¶)", expanded=False):
                for idx, file in enumerate(uploaded_files):
                    file_size_mb = file.size / (1024 * 1024)
                    st.write(f"{idx + 1}. **{file.name}** ({file_size_mb:.2f} MB)")

        st.divider()
        # æ“ä½œæŒ‰é’®
        st.subheader("ğŸ› ï¸ æ“ä½œ")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯", width='stretch', help="æ¸…é™¤æ‰€æœ‰èŠå¤©è®°å½•"):
                clear_chat_history()

    # ========== ä¸»èŠå¤©ç•Œé¢ ==========
    # åˆå§‹åŒ–ç³»ç»Ÿ
    if "system" not in st.session_state:
        with st.spinner("æ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿ..."):
            st.session_state.system = init_system()

    # æ˜¾ç¤ºèŠå¤©å†å²
    chat_container = st.container()

    with chat_container:
        # æ˜¾ç¤ºæ‰€æœ‰æ¶ˆæ¯
        for idx, message in enumerate(st.session_state.messages):
            display_message(message)

        # å¦‚æœè¿˜æ²¡æœ‰æ¶ˆæ¯ï¼Œæ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯
        if not st.session_state.messages:
            st.markdown("""
            <div style='text-align: center; padding: 2rem; color: #666;'>
                <h3>ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ä¼ä¸šæ™ºèƒ½åˆ†æåŠ©æ‰‹</h3>
                <p>ğŸ’¡ ç¤ºä¾‹ï¼š</p>
                <p>â€¢ "åˆ†ææ¬£å¼ºç”µå­(300745)çš„æ’¤å¦åŸå› "</p>
                <p>â€¢ "è¯„ä¼°æŸç§‘æŠ€å…¬å¸é•¿æœŸè¾…å¯¼çš„ä¸Šå¸‚éšœç¢"</p>
                <p>â€¢ "åˆ†ææŸé›†å›¢ä¸Šä¸‹æ¸¸å…³è”å…³ç³»"</p>
            </div>
            """, unsafe_allow_html=True)

    # ========== è¾“å…¥åŒºåŸŸ ==========
    input_container = st.container()

    with input_container:
        st.divider()

        # åˆ›å»ºè¾“å…¥è¡¨å•
        with st.form(key="chat_input_form", clear_on_submit=True):
            col1, col2 = st.columns([5, 1])

            with col1:
                prompt = st.text_area(
                    "è¾“å…¥æ‚¨çš„é—®é¢˜",
                    height=80,
                    placeholder="ä¾‹å¦‚ï¼šåˆ†ææ¬£å¼ºç”µå­(300745)çš„æ’¤å¦åŸå› ã€è¯„ä¼°æŸå…¬å¸çš„ä¸Šå¸‚å¯è¡Œæ€§ã€äº†è§£è¡Œä¸šæœ€æ–°è¶‹åŠ¿ç­‰...",
                    key="chat_input",
                    label_visibility="collapsed",
                    value=st.session_state.get("auto_query", "")
                )

            with col2:
                submit_button = st.form_submit_button(
                    "å‘é€",
                    type="primary",
                    width='stretch'
                )

            if "auto_query" in st.session_state:
                del st.session_state.auto_query

    # ========== å¤„ç†ç”¨æˆ·è¾“å…¥ ==========
    if submit_button and prompt:
        add_message("user", prompt)
        st.rerun()

    elif submit_button and not prompt:
        st.warning("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜")

    # ========== å¤„ç†AIå“åº” ==========
    if (st.session_state.messages and
            st.session_state.messages[-1]["role"] == "user" and
            not hasattr(st.session_state, "processing_message")):

        user_message = st.session_state.messages[-1]["content"]
        st.session_state.processing_message = True

        with chat_container:
            with st.chat_message("assistant"):
                with st.spinner("æ­£åœ¨åˆ†æ..."):
                    try:
                        # è·å–ç³»ç»Ÿå®ä¾‹
                        system = st.session_state.system
                        rag_processor = system["rag_processor"]
                        vectorizer = system["vectorizer"]
                        llm_extractor = system["llm_extractor"]  # è·å–å¤§æ¨¡å‹è¯†åˆ«å™¨

                        # ä½¿ç”¨å¤§æ¨¡å‹æ™ºèƒ½æå–åœºæ™¯å’Œä¼ä¸šä¿¡æ¯

                        extracted_info = llm_extractor.extract_company_and_scenario(user_message)

                        company_code = extracted_info["company_code"]
                        company_name = extracted_info["company_name"]
                        scenario_type = extracted_info["scenario"]
                        scenario_name = extracted_info["scenario_name"]

                        # è·å–åœºæ™¯è§„åˆ™
                        scenario_rule = ScenarioConfig.get_scenario_rule(scenario_type)

                        # ç¡®ä¿åœºæ™¯åç§°ä¸åœºæ™¯è§„åˆ™åŒ¹é…
                        if scenario_rule:
                            scenario_name = scenario_rule.display_name

                        # æ˜¾ç¤ºæå–çš„ä¿¡æ¯
                        info_text = []
                        if company_name:
                            confidence = extracted_info["confidence"]["company"]
                            info_text.append(f"è¯†åˆ«åˆ°ä¼ä¸š: {company_name} (ç½®ä¿¡åº¦: {confidence:.0%})")
                            if company_code:
                                info_text[-1] += f" [ä»£ç : {company_code}]"
                        elif company_code:
                            confidence = extracted_info["confidence"]["company"]
                            info_text.append(f"è¯†åˆ«åˆ°ä¼ä¸šä»£ç : {company_code} (ç½®ä¿¡åº¦: {confidence:.0%})")

                        if scenario_name != "è‡ªå®šä¹‰åˆ†æ":
                            confidence = extracted_info["confidence"]["scenario"]
                            info_text.append(f"è¯†åˆ«åˆ°åœºæ™¯: {scenario_name} (ç½®ä¿¡åº¦: {confidence:.0%})")

                        # ä½¿ç”¨ä¼ä¸šåç§°è¿›è¡Œæœç´¢ï¼ˆä¼˜å…ˆä½¿ç”¨åç§°ï¼Œå…¶æ¬¡ä½¿ç”¨ä»£ç ï¼‰
                        search_company = company_name or company_code

                        # å¤„ç†ä¸Šä¼ çš„PDFæ–‡æ¡£
                        if st.session_state.uploaded_files:
                            pdf_processor = PDFProcessor(system["config"])
                            processed_count = 0

                            for uploaded_file in st.session_state.uploaded_files:
                                temp_dir = tempfile.mkdtemp()
                                temp_path = os.path.join(temp_dir, uploaded_file.name)

                                try:
                                    with open(temp_path, "wb") as f:
                                        f.write(uploaded_file.getbuffer())

                                    chunks = pdf_processor.extract_text_from_pdf(temp_path)
                                    if chunks and isinstance(chunks, list):
                                        success_count = vectorizer.store_documents(chunks)
                                        processed_count += success_count if success_count else 0

                                except Exception as e:
                                    st.error(f"å¤„ç†æ–‡ä»¶ {uploaded_file.name} å¤±è´¥: {e}")
                                finally:
                                    try:
                                        os.remove(temp_path)
                                        os.rmdir(temp_dir)
                                    except:
                                        pass

                            if processed_count > 0:
                                st.info(f"å·²å¤„ç† {processed_count} ä¸ªæ–‡æ¡£ç‰‡æ®µ")

                        # æ‰§è¡Œåˆ†æ
                        result = rag_processor.process_query(
                            query=user_message,
                            scenario=scenario_rule.display_name if scenario_rule else (scenario_name if scenario_name != "è‡ªå®šä¹‰åˆ†æ" else None),
                            company_code=search_company,
                            use_web_data="auto",
                            scenario_rule=scenario_rule
                        )

                        # ç¡®ä¿resultæ˜¯å­—å…¸
                        if not isinstance(result, dict):
                            result = {
                                "response": {
                                    "summary": str(result) if result else "åˆ†æç»“æœä¸ºç©º",
                                    "detailed_analysis": {
                                        "local_based": ["æœ¬åœ°æ–‡æ¡£åˆ†æ"],
                                        "web_based": ["ç½‘ç»œä¿¡æ¯åˆ†æ"],
                                        "integrated": ["ç»¼åˆåˆ†æ"]
                                    },
                                    "key_findings": ["åˆ†æå®Œæˆ"],
                                    "risk_assessment": {
                                        "identified_risks": [],
                                        "risk_level": "æœªçŸ¥",
                                        "rationale": "åˆ†æå®Œæˆ"
                                    },
                                    "recommendations": []
                                },
                                "retrieval_stats": {},
                                "source_documents": [],
                                "query": user_message,
                                "scenario_name": scenario_name,
                                "company_code": company_code,
                                "timestamp": datetime.now().isoformat()
                            }

                        # è·å–å“åº”å†…å®¹
                        response = result.get("response", {})
                        if not isinstance(response, dict):
                            response = {"summary": str(response)}

                        answer = response.get("summary") or "\n".join(response.get("analysis", []))

                        if not answer:
                            answer = "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚è¯·å°è¯•æ›´å…·ä½“çš„é—®é¢˜æˆ–ä¸Šä¼ ç›¸å…³æ–‡æ¡£ã€‚"

                        # æ·»åŠ AIæ¶ˆæ¯åˆ°å†å²
                        add_message("assistant", answer, result)

                    except Exception as e:
                        error_msg = f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"
                        add_message("assistant", error_msg)
                        st.error(f"è¯¦ç»†é”™è¯¯: {e}")

                    finally:
                        if "processing_message" in st.session_state:
                            del st.session_state.processing_message
                        st.rerun()


if __name__ == "__main__":
    main()